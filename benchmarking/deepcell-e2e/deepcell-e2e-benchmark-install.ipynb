{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eae67ef7-86b4-48c8-9fc0-d0dcfacfc248",
   "metadata": {},
   "source": [
    "# End-to-end DeepCell Benchmark\n",
    "\n",
    "**IMPORTANT** - set notebook runtime to `TensorFlow 2.12 (Local)`  \n",
    "This notebook runs an input image through the DeepCell Mesmer application to generate whole-cell cellular segmentation predictions. It benchmarks the above along several measures. (todo: document benchmark CSV output format)\n",
    "\n",
    "This notebook accepts a numpy array of two input channels: the nuclear & membrane channels in that order. The array must be named `input_channels` in an `npz` file.\n",
    "\n",
    "The array is given as a URL, for example: `gs://a-data-bucket/a-path/input_channels.npz`. In principle `smart_open` works for \"all\" cloud providers but I have only tested (+ specified dependencies) for GCS (Google Cloud Storage).\n",
    "\n",
    "The notebook optionally outputs the predicted segments to `predictions_output_path` if provided, into an `npz` file containing a single array: `predictions`.\n",
    "\n",
    "If the `visualize` parameter is `True`, the notebook generates 2 image files: `input_png_output_path` and `predictions_png_output_path`. A green/blue visualization will be written to `input_png_output_path`, and the same visualization with predictions overlaid will be written to `predictions_png_output_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e18c9-1bdd-4517-9b05-048d62e80e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install DeepCell\n",
    "\n",
    "!pip install deepcell --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2803950f-d47a-4d05-9740-3adbac26d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify DeepCell Version\n",
    "\n",
    "import deepcell\n",
    "print(\"DeepCell version:\", deepcell.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf9e518-60f5-4124-87b9-09816ea5bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import csv\n",
    "from datetime import datetime, timezone\n",
    "import deepcell\n",
    "from deepcell.applications import Mesmer\n",
    "import io\n",
    "import logging\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import psutil\n",
    "import re\n",
    "import resource\n",
    "import smart_open\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135481a0-7d86-4ca6-96da-e3726bcbbab7",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Parameters:\n",
    "\n",
    "* `input_channels_path` (required): the URL to the input numpy array containing 2 input channels (nuclear & membrane).\n",
    "* `model_path` : the URL to the MultiplexSegmentation Tensorflow Keras model.\n",
    "* `predictions_output_path` : the URL to write predictions, or `None`/`\"\"` if not saving predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ad943-114f-4403-88c4-5d94a43a5230",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# This cell is a notebook 'parameters' cell.\n",
    "\n",
    "input_channels_path = 'gs://davids-genomics-data-public/cellular-segmentation/deep-cell/vanvalenlab-multiplex-20200810_tissue_dataset/mesmer-sample-3-dev/input_channels.npz'\n",
    "\n",
    "model_path = os.path.expanduser('~') + '/.keras/models/MultiplexSegmentation'\n",
    "\n",
    "predictions_output_path = None\n",
    "# predictions_output_path = 'gs://davids-genomics-data-public/cellular-segmentation/deep-cell/vanvalenlab-multiplex-20200810_tissue_dataset/mesmer-sample-3-dev/segmentation_predictions.npz'\n",
    "\n",
    "# Set to GCP region + instance ID, or None for local execution.\n",
    "notebook_instance_id = None\n",
    "location = 'us-west1'\n",
    "\n",
    "# Set this to True to visualize & save input & prediction.\n",
    "# If true, the paths may be provided to save the visualizations to storage.\n",
    "visualize = True\n",
    "input_png_output_path = predictions_png_output_path = None\n",
    "# input_png_output_path = 'gs://davids-genomics-data-public/cellular-segmentation/deep-cell/vanvalenlab-multiplex-20200810_tissue_dataset/mesmer-sample-3-dev/input.png'\n",
    "# predictions_png_output_path = 'gs://davids-genomics-data-public/cellular-segmentation/deep-cell/vanvalenlab-multiplex-20200810_tissue_dataset/mesmer-sample-3-dev/segmentation_predictions.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349463b3-2c09-40a9-9455-9a2beecb631e",
   "metadata": {},
   "source": [
    "# Benchmark warm-up\n",
    "\n",
    "It takes tens of seconds to load the Mesmer tensorflow model. Let's assume a production environment would have this primed already. Here we handle such priming aka warm-up as well as Python imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fb8c1-4f7c-41e2-a2ce-310859cf859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model warm-up\n",
    "t = timeit.default_timer()\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "print(\"Loaded model in %s s\" % (timeit.default_timer() - t))\n",
    "\n",
    "app = Mesmer(model=model)\n",
    "\n",
    "# Need to reset top-level logging for intercept to work.\n",
    "# I dunno ü§∑üèª‚Äç‚ôÇÔ∏è There's probably a better way to do this...\n",
    "logging.basicConfig(force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9deeaea-4f23-49b8-93ae-cfa35567e91e",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff79408-1b79-4969-8daf-80c5b0298a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Load inputs\n",
    "\n",
    "t = timeit.default_timer()\n",
    "with smart_open.open(input_channels_path, 'rb') as input_channel_file:\n",
    "    with np.load(input_channel_file) as loader:\n",
    "        # An array of shape [height, width, channel] containing intensity of nuclear & membrane channels\n",
    "        input_channels = loader['input_channels']\n",
    "input_load_time_s = timeit.default_timer() - t\n",
    "\n",
    "print('Loaded input in %s s' % input_load_time_s)\n",
    "\n",
    "# Generate predictions\n",
    "\n",
    "## Intercept log (many shenanigans, such hacking)\n",
    "logger = logging.getLogger()\n",
    "old_level = logger.getEffectiveLevel()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logs_buffer = io.StringIO()\n",
    "buffer_log_handler = logging.StreamHandler(logs_buffer)\n",
    "logger.addHandler(buffer_log_handler)\n",
    "\n",
    "## The actual prediction\n",
    "\n",
    "t = timeit.default_timer()\n",
    "\n",
    "try:\n",
    "    segmentation_predictions = app.predict(input_channels[np.newaxis, ...], image_mpp=0.5)[0]\n",
    "    prediction_success = True\n",
    "    \n",
    "except Exception as e:\n",
    "    # The exception is nom-nom'd. Safe? We'll see ü§î\n",
    "    prediction_success = False\n",
    "    logger.error('Prediction exception: %s', e)\n",
    "\n",
    "prediction_time_s = timeit.default_timer() - t\n",
    "total_time_s = timeit.default_timer() - start_time\n",
    "\n",
    "## Undo log intercept\n",
    "logger.removeHandler(buffer_log_handler)\n",
    "logger.setLevel(old_level)\n",
    "\n",
    "## Wrap up\n",
    "print('Prediction finished in %s s' % prediction_time_s)\n",
    "print('Overall operation finished in %s s' % total_time_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9119e9-314a-44e4-9494-db5ec7568d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the intercepted debug logs to extract step timing.\n",
    "\n",
    "debug_logs = logs_buffer.getvalue()\n",
    "pattern = r\"(?sm)Pre-processed data with mesmer_preprocess in (.+?) s.*Model inference finished in (.+?) s.*Post-processed results with mesmer_postprocess in (.+?) s\"\n",
    "match = re.search(re.compile(pattern, re.MULTILINE), debug_logs)\n",
    "\n",
    "if match:\n",
    "    preprocess_time_s = float(match.group(1))\n",
    "    inference_time_s = float(match.group(2))\n",
    "    postprocess_time_s = float(match.group(3))\n",
    "else:\n",
    "    logger.warning(\"Couldn't parse step timings from debug_logs\")\n",
    "    preprocess_time_s = inference_time_s = postprocess_time_s = math.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93beb230-c7a4-4a85-9dc2-bbd86b656ab6",
   "metadata": {},
   "source": [
    "## Save predictions [optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a596cce3-008c-4d63-93f1-c79029e31cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictions_output_path:\n",
    "    with smart_open.open(predictions_output_path, 'wb') as predictions_file:\n",
    "        np.savez_compressed(predictions_file, predictions=segmentation_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcae731-a711-49f2-98b4-c6015c25d3d8",
   "metadata": {},
   "source": [
    "# Visualization [optional]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e596ecf-f950-4963-8eab-def1f1efa082",
   "metadata": {},
   "source": [
    "## Input channel visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d9981-5398-4f61-a167-793a928ca13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize:\n",
    "    from deepcell.utils.plot_utils import create_rgb_image\n",
    "    from PIL import Image\n",
    "\n",
    "    nuclear_color = 'green'\n",
    "    membrane_color = 'blue'\n",
    "\n",
    "    # Create rgb overlay of image data for visualization\n",
    "    # Note that this normalizes the values from \"whatever\" to rgb range 0..1\n",
    "    input_rgb = create_rgb_image(input_channels[np.newaxis, ...], channel_colors=[nuclear_color, membrane_color])[0]\n",
    "\n",
    "    if input_png_output_path:\n",
    "        # The png needs to normalize rgb values from 0..1, so normalize to 0..255\n",
    "        im = Image.fromarray((input_rgb * 255).astype(np.uint8))\n",
    "        with smart_open.open(input_png_output_path, 'wb') as input_png_file:\n",
    "            im.save(input_png_file, mode='RGB')\n",
    "        del im\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.imshow(input_rgb)\n",
    "    ax.set_title('Predictions')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062cf906-2b75-4b56-880f-32eb232b764b",
   "metadata": {},
   "source": [
    "## Prediction overlay visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7737ae-9b36-47d3-a17e-75637b3a6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize:\n",
    "    from deepcell.utils.plot_utils import make_outline_overlay\n",
    "    \n",
    "    overlay_data = make_outline_overlay(\n",
    "        rgb_data=input_rgb[np.newaxis, ...],\n",
    "        predictions=segmentation_predictions[np.newaxis, ...],\n",
    "    )[0]\n",
    "\n",
    "    from PIL import Image\n",
    "\n",
    "    if predictions_png_output_path:\n",
    "        # The rgb values are 0..1, so normalize to 0..255\n",
    "        im = Image.fromarray((overlay_data * 255).astype(np.uint8))\n",
    "        with smart_open.open(predictions_png_output_path, 'wb') as predictions_png_file:\n",
    "            im.save(predictions_png_file, mode='RGB')\n",
    "        del im\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.imshow(overlay_data)\n",
    "    ax.set_title('Predictions')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c598730f-4762-4c1a-ba2c-02698632c039",
   "metadata": {},
   "source": [
    "# Benchmark data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4cca55-1a31-4803-ad62-ac3c3c45d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\n",
    "    'Input file id', 'File size (MB)', 'Benchmark datetime (UTC)',\n",
    "    'Machine type', 'GPU type', '# GPUs',\n",
    "    'Success?', 'Total time (s)', 'Peak memory (GB)',\n",
    "    'Load time (s)', 'Total prediction time (s)', 'Prediction overhead (s)',\n",
    "    'Predict preprocess time (s)', 'Predict inference time (s)', 'Predict postprocess time (s)',\n",
    "    'deepcell-tf version'\n",
    "]\n",
    "\n",
    "parsed_url = urllib.parse.urlparse(input_channels_path)\n",
    "filename = parsed_url.path.split(\"/\")[-2]\n",
    "file_size = round(input_channels.nbytes / 1000 / 1000, 2)\n",
    "\n",
    "if notebook_instance_id:\n",
    "    # For running on vertex AI:\n",
    "    # Shell command:\n",
    "    # $ gcloud notebooks runtimes describe --format=\"value(virtualMachine.virtualMachineConfig.machineType)\" --location=<region> <notebook_id>\n",
    "    machine_type = 'todo-machine'\n",
    "else:\n",
    "    # assume a generic python environment\n",
    "    # See also:\n",
    "    # https://docs.python.org/3.10/library/os.html#os.cpu_count\n",
    "    try:\n",
    "        num_cpus = len(os.sched_getaffinity(0))\n",
    "    except AttributeError:\n",
    "        num_cpus = os.cpu_count()\n",
    "    total_mem = psutil.virtual_memory().total\n",
    "    machine_type = 'local {} CPUs {} GB RAM'.format(num_cpus, round(total_mem/1000000000, 1))\n",
    "\n",
    "peak_mem_b = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss\n",
    "prediction_overhead_s = prediction_time_s - preprocess_time_s - inference_time_s - postprocess_time_s\n",
    "\n",
    "# Write benchmarking data as CSV:\n",
    "\n",
    "output = io.StringIO()\n",
    "writer = csv.writer(output, quoting=csv.QUOTE_NONNUMERIC)\n",
    "writer.writerow(headers)\n",
    "\n",
    "deepcell_version = deepcell.__version__\n",
    "\n",
    "writer.writerow([\n",
    "    filename, file_size, datetime.now(timezone.utc),\n",
    "    machine_type, 'todo-gpu-type', 'todo-gpu-count',\n",
    "    prediction_success, round(total_time_s, 2), round(peak_mem_b / 1000000000, 1),\n",
    "    round(input_load_time_s, 2), round(prediction_time_s, 2), round(prediction_overhead_s, 2),\n",
    "    round(preprocess_time_s, 2), round(inference_time_s, 2), round(postprocess_time_s, 2),\n",
    "    deepcell_version,\n",
    "])\n",
    "\n",
    "print(output.getvalue())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.12 (Local)",
   "language": "python",
   "name": "local-tf2-2-12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
