{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68160983-3cd0-4229-8307-c7fa4b5a4dfe",
   "metadata": {},
   "source": [
    "This notebook demonstrates running the post-process phase, in isolation.\n",
    "\n",
    "It assumes the intermediate input has been saved already. See notes in \"read input files\" below.\n",
    "\n",
    "This was done for performance testing: I wanted a way to run \"just this part\" without needing to redo the rather expensive prediction phase. (E.g. the GPUs aren't working on my intel mac laptop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470657f-92eb-4817-9f5b-07abc935db64",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb717ede-c4ba-480c-b43a-82ec6630e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "168b64de-1e53-4061-a92a-c257bccd2af2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (overridden by notebook parameters)\n",
    "raw_predictions_path = './saves/raw_segmentation_predictions.npz'\n",
    "model_path = os.path.expanduser('~') + '/.keras/models/MultiplexSegmentation'\n",
    "output_path = './saves'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b97a07-4197-4ba1-833e-53797ec4e5cb",
   "metadata": {},
   "source": [
    "### Load Mesmer model & create app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cacc3121-87b3-4475-a831-15c4b7309682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 15:08:09.673697: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Loaded model in 27.350531013013097 s\n"
     ]
    }
   ],
   "source": [
    "from imaging_helpers import make_app\n",
    "\n",
    "app = make_app(model_path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbd4068-b8d0-49cb-a83a-92bc8f2d3145",
   "metadata": {},
   "source": [
    "### Read input files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadbae21-2ceb-484e-a61e-53310abfd8a3",
   "metadata": {},
   "source": [
    "The `output_images` file is a bit unlike all other saved & loaded npz files in these notebooks. It's generated by inserting this code:\n",
    "\n",
    "```\n",
    "        import numpy as np\n",
    "        self.logger.debug('Saving segmentation image')\n",
    "        np.savez_compressed('raw_segmentation_predictions.npz', output_images=output_images)\n",
    "\n",
    "        # Code right after this is:\n",
    "        # Postprocess predictions to create label image\n",
    "        # label_image = self._postprocess(output_images, **postprocess_kwargs)\n",
    "```\n",
    "\n",
    "into the [base application prediction method](https://github.com/vanvalenlab/deepcell-tf/blob/259f35f574290a728cae966cb6f812cdccc2ab38/deepcell/applications/application.py#L393), right before the postprocess call.\n",
    "\n",
    "Then, in your `deepcell-imaging` checkout–where you're running this notebook in `jupyter-lab`–change your virtual environment to be a symlink to your `deepcell-tf` checkout. Something like this:\n",
    "\n",
    "`$venv_path/lib/python3.10/site-packages/deepcell -> $deepcell_tf_checkout/deepcell/`\n",
    "\n",
    "I think there are better ways to set up python environments with \"editable\" installs but ... another problem for another day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44bf5ea5-bc9b-4ffe-bbe1-a668c81afbf9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded output_images in 13.6647123080038 s\n",
      "output_images has dimensions: (1, 9777, 14239, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "t = timeit.default_timer()\n",
    "\n",
    "with np.load(raw_predictions_path, allow_pickle=True) as loader:\n",
    "    output_images = loader['output_images']\n",
    "\n",
    "# this is getting persisted weirdly maybe because it has a dict in it\n",
    "# Doing this transform extracts the single element that was deserialized,\n",
    "# which is a tuple containing (), and the actual images. So we select the\n",
    "# second item of that tuple which at least is the output images we serialized.\n",
    "output_images = list(np.ndenumerate(output_images))[0][1]\n",
    "\n",
    "print('Loaded output_images in %s s' % (timeit.default_timer() - t))\n",
    "print('output_images has dimensions: %s' % (output_images['whole-cell'][0].shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8711755c-68e1-4505-8509-1777533065f1",
   "metadata": {},
   "source": [
    "### Run post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b00d59-5639-4d6b-ae9d-13ebc054be27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidhaley/dev/deepcell-imaging/notebooks/venv/lib/python3.10/site-packages/deepcell_toolbox/deep_watershed.py:108: UserWarning: h_maxima peak finding algorithm was selected, but the provided image is larger than 5k x 5k pixels.This will lead to slow prediction performance.\n",
      "  warnings.warn('h_maxima peak finding algorithm was selected, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-process finished in 285.6167378560058 s\n"
     ]
    }
   ],
   "source": [
    "from deepcell.applications.mesmer import build_postprocessing_kwargs\n",
    "\n",
    "t = timeit.default_timer()\n",
    "\n",
    "# build_postprocessing_kwargs depends on a PR I haven't submitted to vanvalenlab yet. :(\n",
    "postprocess_kwargs = build_postprocessing_kwargs()\n",
    "\n",
    "profiling = 'speedscope'\n",
    "speedscope_output_path = 'speedscope.json'\n",
    "\n",
    "match profiling:\n",
    "  case 'snakeviz':\n",
    "    import snakeviz\n",
    "    %load_ext snakeviz\n",
    "    %snakeviz -t label_image = app._postprocess(output_images, **postprocess_kwargs)\n",
    "  case 'speedscope':\n",
    "    import speedscope\n",
    "    with speedscope.track(speedscope_output_path):\n",
    "        label_image = app._postprocess(output_images, **postprocess_kwargs)\n",
    "  case _:\n",
    "    label_image = app._postprocess(output_images, **postprocess_kwargs)\n",
    "\n",
    "print('Post-process finished in %s s' % (timeit.default_timer() - t))\n",
    "\n",
    "# To open new tab on snakeviz profiling,\n",
    "# $ snakeviz /var/folders/nz/qx4dxfys0_l2tn57sz_dyn440000gn/T/tmp645j9al3\n",
    "# where you use the path from the log: Profile stats marshalled to file '...'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
