{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f794338e-92d6-42aa-9081-b9523fa72374",
   "metadata": {},
   "source": [
    "TIF images → `Extract-Channels` → `Visualize-Inputs` → `Predict-Segments` → `Visualize-Segmentation` → predicted segmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963bcd8-acea-435a-9314-29164d3af360",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc84326-6f88-480b-847c-54842789c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1529342f-35a2-48c5-942f-4bbbdc2463c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters (overridden by notebook parameters)\n",
    "input_channels_path = './saves/input_channels.npz'\n",
    "model_path = os.path.expanduser('~') + '/.keras/models/MultiplexSegmentation'\n",
    "output_path = './saves'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8998861a-6a06-4da0-a659-e5d8eecb01fd",
   "metadata": {},
   "source": [
    "### Load Mesmer model & create app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2b52df-f15e-4bcb-a07f-5c61580f582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 15:25:31.047780: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Loaded model in 25.463194751995616 s\n"
     ]
    }
   ],
   "source": [
    "from imaging_helpers import make_app\n",
    "\n",
    "app = make_app(model_path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e11d02-f0e5-40a9-afad-246b16aedcfe",
   "metadata": {},
   "source": [
    "### Read input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6be53e-98fa-49f8-88f2-0c56f5edb4aa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with np.load(input_channels_path) as loader:\n",
    "    # An array of shape [num_inputs, height, width] containing intensity of nuclear channel\n",
    "    inputs_nuclear = loader['nuclear']\n",
    "\n",
    "    # An array of shape [num_inputs, height, width] containing intensity of membrane channel\n",
    "    inputs_membrane = loader['membrane']\n",
    "\n",
    "# An array of shape [num_inputs, height, width, 2] containing nuclear & membrane channels\n",
    "input_channels = np.stack((inputs_nuclear, inputs_membrane), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9567191d-d8d9-4d8f-8ade-6e1807dffd1e",
   "metadata": {},
   "source": [
    "# Generate predictions\n",
    "\n",
    "This step is expensive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8866adc-5185-4590-9cac-ecaabe6fa186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Converting image dtype to float\n",
      "DEBUG:Mesmer:Pre-processed data with mesmer_preprocess in 53.38774848601315 s\n",
      "DEBUG:Mesmer:Model inference finished in 927.9249126589857 s\n",
      "DEBUG:Mesmer:Post-processing results with mesmer_postprocess and kwargs: {'whole_cell_kwargs': {'maxima_threshold': 0.075, 'maxima_smooth': 0, 'interior_threshold': 0.2, 'interior_smooth': 2, 'small_objects_threshold': 15, 'fill_holes_threshold': 15, 'radius': 2}, 'nuclear_kwargs': {'maxima_threshold': 0.1, 'maxima_smooth': 0, 'interior_threshold': 0.2, 'interior_smooth': 2, 'small_objects_threshold': 15, 'fill_holes_threshold': 15, 'radius': 2}, 'compartment': 'whole-cell'}\n",
      "/Users/davidhaley/dev/deepcell-imaging/notebooks/venv/lib/python3.10/site-packages/deepcell_toolbox/deep_watershed.py:108: UserWarning: h_maxima peak finding algorithm was selected, but the provided image is larger than 5k x 5k pixels.This will lead to slow prediction performance.\n",
      "  warnings.warn('h_maxima peak finding algorithm was selected, '\n",
      "DEBUG:Mesmer:Post-processed results with mesmer_postprocess in 275.2320215930231 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction finished in 1326.915612539975 s\n"
     ]
    }
   ],
   "source": [
    "t = timeit.default_timer()\n",
    "\n",
    "import logging\n",
    "logging.root.setLevel(logging.DEBUG)\n",
    "\n",
    "import tracemalloc\n",
    "tracemalloc.start()\n",
    "segmentation_predictions = app.predict(input_channels, image_mpp=0.5)\n",
    "snapshot = tracemalloc.take_snapshot()\n",
    "tracemalloc.stop()\n",
    "\n",
    "print('Prediction finished in %s s' % (timeit.default_timer() - t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da681ab-ee1d-401e-a5c1-67159a91badc",
   "metadata": {},
   "source": [
    "# Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f178b86-23e6-4ce3-93d5-965963ac029b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 lines\n",
      "#1: <__array_function__ internals>:180: 543818.9 KiB\n",
      "#2: internal/python_message.py:1501: 1160.9 KiB\n",
      "    self._parent_message_weakref = weakref.proxy(parent_message)\n",
      "#3: internal/decoder.py:553: 1017.3 KiB\n",
      "    value = str(byte_str, 'utf-8')\n",
      "#4: framework/ops.py:500: 971.3 KiB\n",
      "    self._consumers = []\n",
      "#5: internal/python_message.py:1465: 762.4 KiB\n",
      "    other_field = self._oneofs.setdefault(field.containing_oneof, field)\n",
      "#6: framework/ops.py:2110: 512.5 KiB\n",
      "    self._graph = g\n",
      "#7: python3.10/abc.py:123: 470.4 KiB\n",
      "    return _abc_subclasscheck(cls, subclass)\n",
      "#8: internal/python_message.py:1338: 412.0 KiB\n",
      "    self._fields[field] = value\n",
      "#9: internal/containers.py:441: 363.6 KiB\n",
      "    new_element = self._message_descriptor._concrete_class()\n",
      "#10: python3.10/linecache.py:137: 334.7 KiB\n",
      "    lines = fp.readlines()\n",
      "1772 other: 6704.6 KiB\n",
      "Total allocated size: 556528.5 KiB\n"
     ]
    }
   ],
   "source": [
    "import linecache\n",
    "def display_top(snapshot, key_type='lineno', limit=3):\n",
    "    snapshot = snapshot.filter_traces((\n",
    "        tracemalloc.Filter(False, \"<frozen importlib._bootstrap>\"),\n",
    "        tracemalloc.Filter(False, \"<unknown>\"),\n",
    "    ))\n",
    "    top_stats = snapshot.statistics(key_type)\n",
    "\n",
    "    print(\"Top %s lines\" % limit)\n",
    "    for index, stat in enumerate(top_stats[:limit], 1):\n",
    "        frame = stat.traceback[0]\n",
    "        # replace \"/path/to/module/file.py\" with \"module/file.py\"\n",
    "        filename = os.sep.join(frame.filename.split(os.sep)[-2:])\n",
    "        print(\"#%s: %s:%s: %.1f KiB\"\n",
    "              % (index, filename, frame.lineno, stat.size / 1024))\n",
    "        line = linecache.getline(frame.filename, frame.lineno).strip()\n",
    "        if line:\n",
    "            print('    %s' % line)\n",
    "\n",
    "    other = top_stats[limit:]\n",
    "    if other:\n",
    "        size = sum(stat.size for stat in other)\n",
    "        print(\"%s other: %.1f KiB\" % (len(other), size / 1024))\n",
    "    total = sum(stat.size for stat in top_stats)\n",
    "    print(\"Total allocated size: %.1f KiB\" % (total / 1024))\n",
    "\n",
    "\n",
    "display_top(snapshot, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e783e555-f6f3-4502-af3d-e2fd1577afdf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez_compressed(output_path + '/segmentation_predictions.npz', predictions=segmentation_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
